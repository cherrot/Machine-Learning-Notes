%% LyX 2.0.0 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[english]{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{fontspec}
\usepackage[a4paper]{geometry}
\geometry{verbose,tmargin=25mm,bmargin=25mm,lmargin=20mm,rmargin=20mm,footskip=15mm}
\usepackage{color}
\usepackage{wrapfig}
\usepackage{graphicx}
\usepackage[unicode=true,
 bookmarks=true,bookmarksnumbered=true,bookmarksopen=true,bookmarksopenlevel=3,
 breaklinks=false,pdfborder={0 0 1},backref=section,colorlinks=true]
 {hyperref}
\hypersetup{
 unicode=false}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
%% A simple dot to overcome graphicx limitations
\newcommand{\lyxdot}{.}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
\newenvironment{lyxcode}
{\par\begin{list}{}{
\setlength{\rightmargin}{\leftmargin}
\setlength{\listparindent}{0pt}% needed for AMS classes
\raggedright
\setlength{\itemsep}{0pt}
\setlength{\parsep}{0pt}
\normalfont\ttfamily}%
 \item[]}
{\end{list}}

\@ifundefined{date}{}{\date{}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
%中英文混排设置%
\usepackage[BoldFont,SlantFont,fallback,CJKchecksingle]{xeCJK}
\setmainfont{DejaVu Serif}%西文衬线字体
\setsansfont{DejaVu Sans}%西文无衬线字体
\setmonofont{DejaVu Sans Mono}%西文等宽字体
\setCJKmainfont{Adobe Song Std}%中文衬线字体
\setCJKsansfont{Adobe Heiti Std}%中文无衬线字体
\setCJKmonofont{WenQuanYi Micro Hei Mono}%中文等宽字体
\punctstyle{banjiao}%半角字符

%其他中文设置%
\XeTeXlinebreaklocale “zh”%中文断行
\XeTeXlinebreakskip = 0pt plus 1pt minus 0.1pt%左右弹性间距
\usepackage{indentfirst}%段落首行缩进
\setlength{\parindent}{2em}%缩进两个字符

%编号语言、样式设置%
\numberwithin{equation}{section}%设置公式按章节进行编号
\numberwithin{figure}{section}% 按章节编号
%\numberwithin{figure}{subsection}% 按子章节编号
\usepackage{footnpag}


%以下内容（\renewcommand）需要放置在\begin{document}之后才能起作用
\renewcommand\arraystretch{1.2}%1.2表示表格中行间距的缩放比例因子(缺省的标准值为1),中文需要更多的间距
\renewcommand{\contentsname}{目录} 
\renewcommand{\listfigurename}{插图目录} 
\renewcommand{\listtablename}{表格目录} 
\renewcommand{\refname}{参考文献} 
\renewcommand{\abstractname}{摘要} 
\renewcommand{\indexname}{索引} 
\renewcommand{\tablename}{表}
\renewcommand{\figurename}{图}
\renewcommand\appendixname{附录}
\renewcommand\partname{部分} 
\renewcommand\today{\number\year年\number\month月\number\day日}

\@ifundefined{showcaptionsetup}{}{%
 \PassOptionsToPackage{caption=false}{subfig}}
\usepackage{subfig}
\AtBeginDocument{
  \def\labelitemi{\(\blacksquare\)}
  \def\labelitemii{\(\blacktriangleright\)}
  \def\labelitemiii{\(\vartriangleright\)}
  \def\labelitemiv{\(\centerdot\)}
}

\makeatother

\usepackage{xunicode}
\usepackage{polyglossia}
\setdefaultlanguage{english}
\begin{document}
\renewcommand\arraystretch{1.2}%1.2表示表格中行间距的缩放比例因子(缺省的标准值为1),中文需要更多的间距
\renewcommand{\contentsname}{目录} 
\renewcommand{\listfigurename}{插图目录} 
\renewcommand{\listtablename}{表格目录} 
\renewcommand{\refname}{参考文献} 
\renewcommand{\abstractname}{摘要} 
\renewcommand{\indexname}{索引} 
\renewcommand{\tablename}{表} 
\renewcommand{\figurename}{图} 
\renewcommand\appendixname{附录} 
\renewcommand\partname{部分} 
\renewcommand\today{\number\year年\number\month月\number\day日}


\title{Machine Learning Notes}


\author{Cherrot Luo}


\date{2011}

\maketitle
\tableofcontents{}\newpage{}


\section{Introduction}


\subsection{Supervised Learning}

e.g. predict the price, predict cancer or not, etc.

We give the algorithm a data set in which the right answer was given.
\begin{description}
\item [{Regression~program}] Predict continuous valued output.
\item [{Classification}] Discrete(离散的) valued output.
\end{description}

\subsection{Unsupervised Learning(Clustering)}

e.g. Google News, Social network clustrering, 鸡尾酒派对问题 etc.
\begin{description}
\item [{singular~value~decomposition}] 奇异值分解。
\end{description}

\section{Linear Regression With One Variable}


\subsection{Model Representation}

卖房子问题
\begin{description}
\item [{Supervised~learning}] Given the {}``right answer'' for each
example in the data.

\begin{description}
\item [{Regression~Problem}] Predict real-valued output.(Classification
Problem 是用来预测离散值的)
\end{description}
\end{description}

\subsubsection{Training Set}
\begin{description}
\item [{m}] Number of training examples.
\item [{x'\textmd{s}}] {}``input'' variable / features.( often also called
purchase)
\item [{y'\textmd{s}}] {}``output'' variable / {}``target'' variable
\item [{$\left(x^{(i)},y^{(i)}\right)$}] 通常的$\left(x_{i},y_{i}\right)$。
\end{description}
单变量（Univariate）线性回归的直观认识可见图\ref{fig:training-set}。

\begin{figure}[tbh]
\centering{}\includegraphics[scale=0.75]{\string"2.1.training set\string".png}\caption{\label{fig:training-set}training set}
\end{figure}



\subsection{Cost Function}

一元Hypothesis的公式$h_{\theta}\left(x\right)=\theta_{0}+\theta_{1}x$,其实就是y=a{*}x+b。$\Theta_{i's}$称为这个模型的参数(Parameters).问题要解决的就是如何选择这两个参数，使数据拟合的误差最小:

\begin{equation}
\underset{\theta_{0}\theta_{1}}{Minimize}\,\frac{1}{2m}\overset{m}{\underset{i=1}{\sum}}\left(h_{\theta}\left(x^{\left(i\right)}\right)-y^{\left(i\right)}\right)^{2}\label{eq: minimize cost function}
\end{equation}


定义cost~function为:
\begin{equation}
J\left(\theta_{0},\theta_{1}\right)=\frac{1}{2m}\overset{m}{\underset{i=1}{\sum}}\left(h_{\theta}\left(x^{\left(i\right)}\right)-y^{\left(i\right)}\right)^{2}\label{eq:cost function of univariate hypothesis}
\end{equation}


(方差的二分之一)


\subsection{Cost function intuition I}

如果$\theta_{0}=0$,那么cost function 是二维坐标系的弓形（一元二次方程）。


\subsection{Cost function intuition II}

cost function 如图\ref{fig:Cost-Function=007684=0076F4=0089C2=008868=00793A}所示，自变量是$\theta_{0}$和$\theta_{1}$(这种形状称为凸函数
convex funtion)：

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"2.3.cost function\string".png}
\par\end{centering}

\caption{\label{fig:Cost-Function=007684=0076F4=0089C2=008868=00793A}Cost
Function的直观表示}


\end{figure}


contour~plot（等值线图）可以更清楚直观的表示出Cost Function的收敛趋势，如图\ref{fig:=007B49=00503C=007EBF=0056FE(Contour-Plot)}所示。

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"2.3.contour plot\string".png}
\par\end{centering}

\caption{\label{fig:=007B49=00503C=007EBF=0056FE(Contour-Plot)}等值线图(Contour
Plot)}
\end{figure}



\subsection{Gradient descent -- 求最小J($\theta_{0},\theta_{1}$)的算法}

$\theta$的初始值习惯上全部置为零（当然取别的值也无所谓）%
\footnote{在神经网络中，$\Theta$的初始值却不能全部为0，详见\ref{sub:Random-Initialization}。%
}。使用该算法得到的是局部最优解，不一定是全局最优解，如图\ref{fig:Gradient-Descent=007684=008FC7=007A0B}所示，如果起始点不同，那么可能会得到不同的局部最优解（local
optimal）。

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"2.4.gradient descent\string".png}
\par\end{centering}

\caption{\label{fig:Gradient-Descent=007684=008FC7=007A0B}Gradient Descent的过程}
\end{figure}


数学描述：

repeat until convergence\{

\qquad{}$\theta_{j}:=\theta_{j}-\alpha\frac{\partial}{\partial\theta_{j}}J\left(\theta_{0},\theta_{1}\right)\; for\, j=0\, and\, j=1$

\}
\begin{description}
\item [{:=}] 赋值号
\item [{$\alpha$}] learning rate. Controls how big a step we take downhill
with gradient descent.即梯度值，是个正数。
\item [{偏导数(partial~derivative~term)}] 见下一节。偏导数和导数(用d而不是$\partial$表示)的区别在于参数个数,该题中有两个参数，只对一个求导，所以是偏导(partial)。
\end{description}
注意，我们需要同时更新(Simultaneous update)$\theta_{0}$和$\theta_{1}$（见图\ref{fig:=00540C=006B65=0066F4=0065B0}）。

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"2.5\string". simultaneous update}
\par\end{centering}

\caption{\label{fig:=00540C=006B65=0066F4=0065B0}同步更新}


\end{figure}



\subsection{Gradient descent intuition}

见图\ref{fig:=0076F4=0089C2=007406=0089E3Gradient-Descent}，以$\theta_{1}$为例，如果落点在最小点右边，那么函数偏导是负数，$\theta_{1}$的值会随之减小（向最小点靠近）；如果落点在最小点左边，那么求导结果是负数，那么$\theta_{1}$的值会随之增大。最终的结果就是使$\theta_{1}$落在或逼近最小点。

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"2.5\string".gradient descent intuition}
\par\end{centering}

\caption{\label{fig:=0076F4=0089C2=007406=0089E3Gradient-Descent}直观理解Gradient
Descent}


\end{figure}



\subsection{Gradient descent for linear regression}

“Batch'' Gradient Descent. Each step of gradient descent uses all
the training examples.


\section{Linear Algebra Review}


\subsection{Matrices \& Vectors}

$\mathbb{R}^{4\times2}$表示4行2列的实数矩阵。
\begin{description}
\item [{Vector}] $n\times1$的矩阵。$\mathbb{R}^{n}$表示n维的实数向量。
\end{description}

\subsection{加法}


\subsection{矩阵X向量}

矩阵X向量，矩阵的列数=向量的行数，得到的是另一个向量。

一般的矩阵乘法规则如下：

简单来说就是行X列，用“\textbf{行列式}”来记忆它的运算顺序吧，恰好得到的结果是前面矩阵的行数X后面矩阵的列数的新矩阵。

做乘法必须保证前面矩阵的列数=后面矩阵的行数，可以用“\textbf{前列腺}”来记忆……、


\subsection{矩阵X矩阵}

很简单，矩阵和一个个的向量分别计算得到一个个的结果向量，然后组成新矩阵，可见图\ref{fig:=0077E9=009635=0076F8=004E58=00793A=00610F=0056FE}

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"3.4.matrix multiply\string".png}
\par\end{centering}

\caption{\label{fig:=0077E9=009635=0076F8=004E58=00793A=00610F=0056FE}矩阵相乘示意图}


\end{figure}



\subsection{矩阵乘法的性质}

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"3.5.Not commutative\string".png}
\par\end{centering}

\caption{\label{fig:=0077E9=009635=0076F8=004E58=004E0D=007B26=005408=004EA4=006362=005F8B}矩阵相乘不符合交换律}


\end{figure}

\begin{enumerate}
\item Not Commutative 不符合交换律，如图\ref{fig:=0077E9=009635=0076F8=004E58=004E0D=007B26=005408=004EA4=006362=005F8B}所示。
\item associative符合结合律（也符合分配律）
\item Identity Matrix单位矩阵\\
$A\cdot I=I\cdot A=A$，这里I是单位矩阵，但注意两个I并不一定相同（$m\times n$和$n\times m$）。
\end{enumerate}

\subsection{矩阵求逆Inverse和转置Transpose}


\subsubsection{求逆：}

\begin{equation}
AA^{-1}=A^{-1}A=I\label{eq:=0077E9=009635=006C42=009006}
\end{equation}


其中A为方阵（Square Matrix），只有方阵可以求逆。教材没有给出矩阵求逆的算法，而是用软件（Octave）实现的：pinv(A)


\subsubsection{转置}

记矩阵$A$的转置为$A^{T}$，$A_{ij}=A_{ji}^{T}$

\begin{equation}
\left(AB\right)^{T}=B^{T}A^{T}\label{eq:=008F6C=007F6E=0077E9=009635=007684=006027=008D28}
\end{equation}



\section{Linear Regression with Multiple Variables}


\subsection{Multiple Features}

Notation:

n = number of features

$x^{\left(i\right)}$ = input (features) of $i^{th}$ training example.
对应训练集中的一条输入（一个向量）

$x_{j}^{\left(i\right)}$ = value of feature j in $i^{th}$ training
example. 向量$x^{\left(i\right)}$中的第j项。

多个feature的Hypothesis：$h_{\theta}\left(x\right)=\theta_{0}+\theta_{1}x_{1}+\theta_{2}x_{2}+\cdots+\theta_{n}x_{n}$

假设$x_{0}=1$，且将x和$\theta$均表示为向量，那么上式可写为：

\begin{equation}
h_{\theta}\left(x\right)=\theta^{T}x\label{eq:hypothesis-fuction(multiple-features)}
\end{equation}


通常被称作 multivariate linear regression（多元线性回归）


\subsection{Gradient descent for multiple variables}

Hypothesis：$h_{\theta}\left(x\right)=\theta_{0}+\theta_{1}x_{1}+\theta_{2}x_{2}+\cdots+\theta_{n}x_{n}$

Parameters: 将参数$\theta$看作n+1维的向量$\theta$。

Cost function: $J\left(\theta\right)=\frac{1}{2m}\overset{m}{\underset{i=1}{\sum}}\left(h_{\theta}\left(x^{\left(i\right)}\right)-y^{\left(i\right)}\right)^{2}$

Gradient descent:

\qquad{}Repeat\{

\qquad{}$\theta_{j}:=\theta_{j}-\alpha\frac{\delta}{\delta\theta_{j}}J\left(\theta\right)$

\qquad{}\}

多变量Gradient Descent如图\ref{fig:=00591A=0053D8=0091CF=007684Gradient-Descent}所示。

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"4.2.Gradient Descent\string".png}
\par\end{centering}

\caption{\label{fig:=00591A=0053D8=0091CF=007684Gradient-Descent}多变量的Gradient
Descent}


\end{figure}



\subsection{Gradient descent in practice I:Feature Scaling\label{sub:Gradient-descent-in-practice-1-feature-scaling}}

Make sure features are on a similar scale。

推荐的方案是把Feature的值控制在-1到1（或其他一个相近的）范围内，便于快速收敛。

\begin{figure}[tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"4.3.feature scaling\string".png}
\par\end{centering}

\caption{Feature Scaling}


\end{figure}


如上例，两个feature相差3个数量级，这样就会导致 contour plot （等值线图）画出来非常的陡长（一个个很长的椭圆）。这样导致的后果便是，
Gradient desent 需要很长的时间才能收敛到最优解。


\subsubsection{Mean（平均值） normalization}

将$x_{i}$替换为$x_{i}-\mu_{i}$使features的平均值接近于0。

结合这两种方法，我们可以使$x_{i}$取如图\ref{fig:Mean-Normalization}所示的值。

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"4.3.Mean normalization\string".png}
\par\end{centering}

\caption{\label{fig:Mean-Normalization}Mean Normalization}


\end{figure}



\subsection{Gradient descent in practice II: Learning rate(\textmd{$\alpha$})}

$\alpha$太大可能不收敛，太小可能收敛太慢。来回试吧\textasciitilde{}


\subsection{Features and polynomial regression}

可以根据已有的feature定义新的feature来简化模型。比如卖房子的例子，假定我们有房子的长和宽两个feature，那么我可以定义房子的面积作为一个新的feature，这样就只剩下一个feature就是房子的面积了。

另外可以使用多项式回归的方法，定义原feature的平方、立方等，增大数据拟合的精确度，如图\ref{fig:=00591A=009879=005F0F=0062DF=005408}所示。

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"4.5.Polynomial regression\string".png}
\par\end{centering}

\caption{\label{fig:=00591A=009879=005F0F=0062DF=005408}多项式拟合}


\end{figure}



\subsection{Normal equation 正规方程\label{sub:Normal-equation-=006B63=0089C4=0065B9=007A0B}}
\begin{description}
\item [{Normal~equation}] Method to solve for $\theta$ analytically.
\end{description}
\begin{figure}[!tbh]
\subfloat[X为design matrix]{\begin{centering}
\includegraphics[width=0.7\paperwidth]{\string"4.6.Normal equation\string".png}
\par\end{centering}



}

\subfloat[构造design matrix]{\begin{centering}
\includegraphics[width=0.7\paperwidth]{\string"4.6.Normal Equation3\string".png}
\par\end{centering}



}

\caption{\label{fig:Normal-equation}构造Normal equation}


\end{figure}


将features和y表示成如图\ref{fig:Normal-equation}所示的矩阵 (design matrix) 和向量的形式后，最小化cost
function的$\theta$值为（课程并没有给出这个公式的证明）：

\begin{equation}
\theta=\left(X^{T}X\right)^{-1}X^{T}y\label{eq:normal equation}
\end{equation}


在Octave中表示为pinv( x' {*}x ) {*}x' {*}y。

使用normal equation时，feature scaling和mean normalization没有必要。

图\ref{fig:Gradient-Descent-Normal-Equation}表示的是Gradient Descent和Normal
Equation的区别：

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"4.6.Normal Equation2\string".png}
\par\end{centering}

\caption{\label{fig:Gradient-Descent-Normal-Equation}Gradient Descent 与 Normal
Equation的区别}
\end{figure}


当n不是很大时，使用normal equation是个很好的选择。然而n很大时，normal equation的代价相当昂贵。


\subsection{Normal equation and non-invertibility(不可逆性)}

\begin{equation}
\theta=\left(X^{T}X\right)^{-1}X^{T}y
\end{equation}


$X^{T}X$如果是不可逆的怎么办（虽然很少见）？（sigular/degenerate）%
\footnote{矩阵$A_{n\times n}$可逆的充分必要条件是$A$的行列式$\left|A\right|\neq0$%
}

Octave中pinv和inv的区别：pinv是pseudo inverse,伪求逆，即使矩阵不可逆他也可以求得我们需要的结果。


\subsubsection{$X^{T}X$不可逆的原因？}
\begin{itemize}
\item Redundant features(linearly dependenta存在\textbf{线性}依赖).\\
E.g. $x_{1}=size\, in\, feet^{2}$, $x_{2}=size\, in\, m^{2}$
\item Too many features(e.g. $m\leq n$)\\
Delete some features, or use regularization(talk later).
\end{itemize}

\section{Octave Tutorial}


\subsection{Basic operations}
\begin{itemize}
\item 声明矩阵：v={[}1 2; 3 4{]}
\item v= 1:0.2:2 的意思是，得到一个行向量（一行N列的矩阵），以1开始，到2结束，每次递增0.2。
\item v=1:6 得到1到6递增1的整数行向量。
\item disp()显示函数，使用它输出的结果不会带有ans=前缀。
\item sprintf() 与C语言相似的格式输出函数。
\item ones(2,3) 产生一个2{*}3的全是1的矩阵。
\item zeros(3,5) 同理。
\item rand(1,3)得到一个1{*}3的介于0到1的随机数矩阵。（如果是方阵，只写一个参数即可）
\item randn(1,3) Gaussian random variable。得到的随机数呈0对称的高斯（正态）分布
\item hist(w) 绘制w的分布直方图 hist(w,50)，显示50个统计条。
\item eye(4) 产生4维的单位矩阵。eye是I的同音。
\end{itemize}

\subsection{Moving data around}
\begin{itemize}
\item size(A)，返回A的尺寸，如果A是矩阵，则返回A的行数和列数。比如A是3{*}2的矩阵，那么该命令返回一个矩阵{[}3, 2{]}。如果执行size(A,
1)将返回3，size(A, 2)返回2.
\item length(A) 返回A较大的维数（可能是行数也可能是列数）。
\item pwd 该变量保存Octave的当前工作目录（如/home/cherrot）。可以使用cd命令切换目录。
\item who 用于显示当前环境中的所有变量。whos给出细节
\item load 文件名 / load('文件名') ：加载数据文件。
\item clear 变量名：清除变量。如果不跟变量则清除所有。
\item v=priceY(1:10) ：将priceY的前10个元素赋值给v
\item save hello.mat v ：将v存到文件hello.mat中。默认为二进制形式。可以加参数 -ascii 以存为文本格式。
\item A(3,2) ：返回$A_{3,2}$（从1开始, 1-indexed）\\
A(3,:) ：返回A第三行的所有元素。“:”代表该行/列的每一个元素\\
A( {[}1 3{]}, :) ：返回第一行和第三行的所有元素
\item A={[}A, {[}5; 6; 7{]}{]} ：将向量{[}5; 6; 7{]}附加在A后面（右边）。
\item A(:) 将A的所有元素打印成一个向量。
\item C={[}A B{]} ：将矩阵A、B左右拼接（也可以用逗号分隔）。
\item C={[}A; B{]} ：将矩阵A、B上下拼接。
\end{itemize}

\subsection{Computing on Data}
\begin{itemize}
\item A{*}B 矩阵乘法
\item Element wise operations 比如A .{*} B 将A中的\textbf{每个元素}与B中对应\textbf{元素}相乘构成新矩阵。\\
点号在常被用于指示element wise operations。比如A .\textasciicircum{}2 的结果是A中每个元素都平方。
\item 对矩阵应用log()或者abs()函数时，同样是element wise operation。对矩阵取反、加/减一个常数值、大小比较都将看作是element
wise operation。
\item A' ：A的转置。
\item max(A)：如果A是矩阵，则返回A中每一列的最大元素；如果A是向量或行向量，则返回A中最大元素，而且如果写作{[}value, index{]}
= max(A)，将返回值和其index。
\item find(V<3)：返回向量V中小于3的元素下标\\
如果要find一个矩阵，可以写成{[}i, j{]} = find(A)。对应的i和j分别为找到元素的行列index。
\item magic(n): 创建一个n{*}n (n!=2)的magic方阵。即每行、每列和两对角线上的元素和都为同一个数。
\item sum() 求和。如果sum(A,\textbf{1})则对A每一列求和，等效于sum(A) 。\\
sum(A,\textbf{2})对每一行求和。
\item prod() 求积
\item floor()向下取整
\item ceil()向上取整
\item max(A, {[}{]}, \textbf{1}) :column wise maximum。找到每列的最大值，得到一个行向量。1
means to take max along the first dimension of A.
\item max(A, {[}{]}, \textbf{2}) :row wise maximum。找到每行的最大值，得到一个向量
\item 要想找到矩阵A中的最大值，可以max(max(A)),或者max(A(:))——即先将A表示成一个向量，在求最大值。
\item flipud() ：flip up \& down，上下颠倒。故flipud(eye(3))的效果就是把单位矩阵的对角线对换。
\end{itemize}

\subsection{Plotting data}

如果要在一个Figure面板中绘制两个曲线，那么需要调用hold on命令：\\
plot(t, y1);\\
hold on;\\
plot(t, y2, 'r'); \% 'r'表示本事件的颜色为红色。\\
xlabel('time')\\
ylabel('value')\\
legend('sin', 'cos') \%添加图例。\\
title('my plot')\\
print -dpng 'myPlot.png' \%保存为png文件\\
close \%关闭plot

如果要绘制多于一个的图像时：\\
figure(1); plot(t, y1);\\
figure(2); plot(t, y2);

如果要在一个figure中绘制两个图，可以使用subplot\\
subplot(1, 2, 1); \%Divides plot a 1x2 grid, access first element\\
plot(t, y1);\\
subplot(1, 2, 2);\\
plot(t, y2);\\
axis({[}0.5 1 -1 1{]}); \%改变右边图片的x y坐标范围，x从0.5到1，y从-1到1。\\
clf; \%清空图像

如果要“绘制”一个矩阵：\\
A=magic(5) \%生成一个矩阵\\
imagesc(A)

或者改成灰度显示一个矩阵：\\
imagesc(A), colorbar, colormap gray; \%逗号可以使多个函数写在一行并且不屏蔽输出（异于分号）。


\subsection{For, While, If statements, and Functions}


\subsubsection{For}

e.g.1：
\begin{lyxcode}
v~=~zeros(10,1);

for~i=1:10,
\begin{lyxcode}
v(i)~=~2\textasciicircum{}i;
\end{lyxcode}
end;
\end{lyxcode}
e.g.2：
\begin{lyxcode}
indices~=~1:10;~\%indices~初始化为一个行向量

for~i~=~indices
\begin{lyxcode}
disp(i);
\end{lyxcode}
end;
\end{lyxcode}

\subsubsection{While}

e.g.1
\begin{lyxcode}
i~=~1;

while~i~<=~5,
\begin{lyxcode}
v(i)~=~100;

i~=~i~+1;
\end{lyxcode}
end;
\end{lyxcode}
e.g.2 使用break;
\begin{lyxcode}
i~=~1;

while~true,
\begin{lyxcode}
v(i)~=~999;

i~=~i~+~1;

if~i~==~6,
\begin{lyxcode}
break;
\end{lyxcode}
end;
\end{lyxcode}
end;
\end{lyxcode}

\subsubsection{If-else}

e.g.1
\begin{lyxcode}
if~v(1)~==~1,
\begin{lyxcode}
disp('one');
\end{lyxcode}
elseif~v(1)~==~2,
\begin{lyxcode}
disp('two');
\end{lyxcode}
else~\%这里没有逗号？
\begin{lyxcode}
disp('other');
\end{lyxcode}
end;
\end{lyxcode}

\subsubsection{Funtions}

Octave定义函数的方式为把函数写四则算法在一个 function\_name.m 文件中。文件内容范例：
\begin{lyxcode}
function~y~=~function\_name(x)

y~=~x\textasciicircum{}2;
\end{lyxcode}
定义的函数文件必须在当前工作目录或者Octave的search path下。可以通过addpath('new\_path')函数来增加search
path

Octave的函数可以返回多值，比如返回{[}y1,y2{]}。


\subsection{Vectorization 向量化}

把变量向量化使计算更加高效（Octave擅长矩阵运算），而且代码量更小（减少了循环等流程控制语句的使用）。


\section{Logistic Regression}


\subsection{Classification}

Classification 仍然属于 Supervised Learning，只不过是离散的值

应用场景：
\begin{itemize}
\item Email: Spam / Not Spam
\item Online Transactions(交易): Fraudulent(欺诈)?
\item Tumor(肿瘤); Malignant / Benign？
\end{itemize}
本节将讨论 binary classification， multi-class classification 将在以后讨论。

一种做法是继续使用线性回归$h_{\theta}\left(x\right)$预测，然后定一个阈值(Threshold Classifier)，比如取0.5作为阈值，如果$h_{\theta}\left(x\right)\geq0.5$，则预测y=1，否则预测y=0。但是这并不合适：

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"6.1 Binary claffication\string".png}
\par\end{centering}

\caption{\label{fig:=004F7F=007528=007EBF=006027=0056DE=005F52=005904=007406Classification}使用线性回归处理Classification的问题}


\end{figure}


正如图\ref{fig:=004F7F=007528=007EBF=006027=0056DE=005F52=005904=007406Classification}所示，假设没有最右边的值，回归曲线应该是洋红色的这条，那么我们取阈值为0.5，预测的结果完全符合样本。然而，如果多了最右侧的这个取值时，回归曲线看起来应该像蓝色这条一样，当我们取阈值0.5时可以发现，预测值不再符合样本了。
\begin{description}
\item [{Logistic~Regression:}] 总能产生$0\leq h_{\theta}\leq1$的$h_{\theta}$的算法（在y=0
或 y=1 的binary classification的情况下）。
\end{description}

\subsection{Hypothesis Representation}

为了得到$0\leq h_{\theta}\left(x\right)\leq1$，则定义

\begin{equation}
h_{\theta}\left(x\right)=g\left(\theta^{T}x\right)\label{eq:logistic regression hypothesis}
\end{equation}


其中

\begin{equation}
g\left(z\right)=\frac{1}{1+e^{-z}}\label{eq:sigmoid function}
\end{equation}


上式称为sigmoid function（S形函数) 或 logistic function（逻辑函数）。$\theta^{T}x$可见公式\ref{eq:hypothesis-fuction(multiple-features)}。公式\ref{eq:sigmoid function}的图形如所示：

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"6.2.sigmoid function\string".png}
\par\end{centering}

\caption{sigmoid function}


\end{figure}



\subsubsection{Interpretation(解释) of Hypothesis Output}

$h_{\theta}\left(x\right)=P\left(y=1\mid x;\,\theta\right)$. It \textbf{estimats}
probability that y=1, given x, parameterized by $\theta$. 


\subsection{Decision Boundary}

只有当$z\geq0$时，$g\left(z\right)\geq0.5$才成立，故只有$\theta^{T}x\geq0$时，$h_{\theta}\left(x\right)\geq0.5$才成立。

Decision Boundary 就是使$\theta^{T}x=0$的直线，如图\ref{fig:Decision-Boundary}所示：

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"6.3.Decision boundary\string".png}
\par\end{centering}

\caption{\label{fig:Decision-Boundary}Decision Boundary}


\end{figure}


图\ref{fig:Decision-Boundary}中$x_{1}+x_{2}=3$这条线就是Decision Boundary。


\subsection{Cost function}

如果将线性回归中的 cost function 用到这里的话，那么我们得到的将是一个 non-convex （非凸函数）的图形（因为$h_{\theta}\left(x\right)$不是一个线性函数，而是一个平方代价函数squre
cost function），导致得不到全局最优解，如图\ref{fig:=0076F4=0063A5=004F7F=007528=007EBF=006027=0056DE=005F52=007684cost-function=005BFC=0081F4=007ED3=00679C=004E3A=00975E=0051F8=0051FD=006570}所示。

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"6.4\string".Cost Function}
\par\end{centering}

\caption{\label{fig:=0076F4=0063A5=004F7F=007528=007EBF=006027=0056DE=005F52=007684cost-function=005BFC=0081F4=007ED3=00679C=004E3A=00975E=0051F8=0051FD=006570}直接使用线性回归的cost
function导致结果为非凸函数}


\end{figure}


下面是Classification情况下的Cost function(with single training example)：

\begin{equation}
J\left(\theta\right)=\frac{1}{m}\sum_{i=1}^{m}Cost\left(h_{\theta}\left(x^{\left(i\right)}\right),y^{\left(i\right)}\right)\label{eq:cost function in classification}
\end{equation}


其中,

\begin{equation}
Cost\left(h_{\theta}\left(x\right),y\right)=\begin{cases}
-\log\left(h_{\theta}\left(x\right)\right) & if\, y=1\\
-\log\left(1-h_{\theta}\left(x\right)\right) & if\, y=0
\end{cases}\label{eq:Cost function in classifcation-Cost-2line}
\end{equation}


函数的图形可以直观的告诉我们上式的作用：

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"6.3.Plot Cost function\string".png}
\par\end{centering}

\caption{Plotting the Cost()}


\end{figure}


为方便计算，公式\ref{eq:Cost function in classifcation-Cost-2line}可写为式\ref{eq:Cost function in classifcation-Cost-1line}的形式。

\begin{equation}
Cost\left(h_{\theta}\left(x\right),y\right)=-y\log\left(h_{\theta}\left(x\right)\right)-\left(1-y\right)\log\left(1-h_{\theta}\left(x\right)\right)\label{eq:Cost function in classifcation-Cost-1line}
\end{equation}


这里要注意当y=1时它的几个特性，如图\ref{fig:Cost=0051FD=006570(Classification)}所示的。在y=1时，当$h_{\theta}\left(x\right)=1$时，Cost为0，也就是没有误差；相反，若$h_{\theta}\left(x\right)\rightarrow0$，那么则视为误差无限大，即Cost趋向于无穷。

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"6.3.Cost function\string".png}
\par\end{centering}

\caption{$Cost\left(h_{\theta}\left(x^{\left(i\right)}\right),y^{\left(i\right)}\right)$函数\label{fig:Cost=0051FD=006570(Classification)}}


\end{figure}


The topic of convexity analysis is beyond the scope of this course.


\subsection{Simplified cost function and gradient descent}

\begin{equation}
J\left(\theta\right)=\frac{1}{m}\sum_{i=1}^{m}Cost\left(h_{\theta}\left(x^{\left(i\right)}\right),y^{\left(i\right)}\right)=-\frac{1}{m}\left[\sum_{i=1}^{m}y^{\left(i\right)}\log h_{\theta}\left(x^{\left(i\right)}\right)+\left(1-y^{\left(i\right)}\right)\log\left(1-h_{\theta}\left(x^{\left(i\right)}\right)\right)\right]\label{eq:simplified cost function for logistic regression}
\end{equation}


之所以使用这个公式作为Cost Function而不是使用其他的公式是因为 This cost function can be derived
from statistics using the \textbf{principle of maximum likelihood
estimation（最大似然估计）,} and it is convex. 更多的细节超出了本课程的讨论范围。

给出上式，我们需要寻找到合适的$\theta$满足$\underset{\theta}{\min}J\left(\theta\right)$，从而就可以计算$h_{\theta}\left(x\right)$了。


\subsubsection{Gradient Descent}

Repeat\{

$\theta_{j}\,:=\theta_{j}-\alpha\frac{\delta}{\delta\theta_{j}}J\left(\theta\right)$

\}(simultaneously update all $\theta_{j}$)

其中$\frac{\delta}{\delta\theta_{j}}J\left(\theta\right)=\frac{1}{m}\sum_{i=1}^{m}\left(h_{\theta}\left(x^{\left(i\right)}\right)-y^{\left(i\right)}\right)x_{j}^{\left(i\right)}$，和线性回归的结果\textbf{相似}%
\footnote{\textbf{怎么算的？} 我的猜想是，sigmoid函数只是起函数域的限定作用，不改变原函数的增长性，所以为了计算简便，求导时不考虑sigmoid函数。求证。%
}，见\ref{fig:=00591A=0053D8=0091CF=007684Gradient-Descent}。\textbf{\label{why:gradient descent=006C42=005BFC=00516C=005F0F=007591=0095EE}}

该算法同样可以使用feature scaling（见\ref{sub:Gradient-descent-in-practice-1-feature-scaling}节）来优化计算。


\subsection{Advanced Optimization}

Optimaization algorithms:
\begin{itemize}
\item Gradient descent
\item Conjugate gradient
\item BFGS
\item L-BFGS
\end{itemize}
其他三个算法具体是怎么做的将不在本课程中涉及。这些算法的缺点是非常复杂，而优点是：
\begin{itemize}
\item No need to manually pick $\alpha$
\item Often faster than gradient descent.
\end{itemize}
We can think of these algorithms as having a clever inter-loop. In
fact the inter-loop is called the \textbf{line search} algorithm that
automatically tries out different values for $\alpha$ and automatically
picks a good learning rate so that it can even pick a different alpha
for every interation.

本课程将不详细的讨论这些算法内部究竟是怎样工作的。作者使用这些算法好多年后才去探索它们是如何工作的=.=

而且不建议自己写代码实现这些代码，有类库干吗不用？例如使用octave的自建函数fminunc更好的实现gradient descent：（图\ref{fig:fminunc=0051FD=006570=007684=004F7F=007528=00793A=004F8B}）

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"6.6.Gradient Example using Octave\string".png}
\par\end{centering}

\caption{\label{fig:fminunc=0051FD=006570=007684=004F7F=007528=00793A=004F8B}fminunc函数的使用示例}


\end{figure}


fminunc()函数：function minimization unconstrained。 是Octave中的内建函数，@表示一个指向函数的指针
(function handle)。fminunc的作用就是计算使给定函数取值最小的参数值，如图\ref{fig:Octave=006F14=00793Afminunc=0051FD=006570}所示即为Octave的演示：

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"6.6.Exercise using Octave\string".png}
\par\end{centering}

\caption{\label{fig:Octave=006F14=00793Afminunc=0051FD=006570}Octave演示fminunc函数}


\end{figure}


options是存储我们需要的option的数据结构。 'GradObj', 'on' sets the gradient objective
parameter to on. It just means you are indeed going to provide a gradient
to this algorithm. 其中exitFlag=1表示算法成功收敛(converge)了。optTheta和functionVal都得到了期望的值（functionVal=0）。注意要使用这个函数，initialTheta必须是不小于二维的向量。
\begin{itemize}
\item Octvave语法：@(t) ( costFunction(t, X, y) ) . This creates a function,
with argument t, which calls your costFunction.（实例见编程作业2）
\end{itemize}
\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"6.6.Cost Function in Octave\string".png}
\par\end{centering}

\caption{\label{fig:=004F7F=007528fminunc=0065F6=009700=008981=0081EA=005B9A=004E49=007684=0051FD=006570}使用fminunc时需要自定义的函数}


\end{figure}


What we need to do is \textbf{write a function that returns the cost
and returns the gradient}（见图\ref{fig:=004F7F=007528fminunc=0065F6=009700=008981=0081EA=005B9A=004E49=007684=0051FD=006570}）.
当然，我们甚至可以将这个算法使用在线性回归问题上。


\subsection{Multi-class classification: One-vs-All}

实例：
\begin{itemize}
\item 标记E-mail类型：Wor, Friends, Family, Hobby。
\item 诊断：Not ill, Cold, Flu
\item 天气：Sunny, Cloudy, Rain, Snow
\end{itemize}
\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"6.7\string".Multi class classification:One-vs-All}
\par\end{centering}

\caption{\label{fig:Multi-class-classification-=0095EE=009898}Multi-class
classification 问题}


\end{figure}



\subsubsection{One-vs-all(one-vs-rest)}

\begin{wrapfigure}{o}{0\columnwidth}%
\includegraphics[scale=0.75]{6.7.multi-classification}\end{wrapfigure}%
What we are going to do is take a training set, and turn this into
three \textbf{separate binary classification problems:}(如图\ref{fig:Multi-class=007684=005206=0089E3}所示)

\begin{figure}[tb]
\begin{centering}
\subfloat[]{\includegraphics[scale=0.75]{6.7.ones-vs-all1}



}\subfloat[]{\includegraphics[scale=0.75]{6\lyxdot 7\lyxdot ones-vs-all2}



}\subfloat[]{\includegraphics[scale=0.75]{6\lyxdot 7\lyxdot ones-vs-all3}



}
\par\end{centering}

\caption{\label{fig:Multi-class=007684=005206=0089E3}Multi-class的分解}


\end{figure}


\begin{equation}
h_{\theta}\left(x\right)=P\left(y=i\mid x;\theta\right),\,\,\left(i=1,2,3\right)\label{eq:hypothesis of multi-class:one-vs-all}
\end{equation}


Train a logistic regression classifier $h_{\theta}^{\left(i\right)}\left(x\right)$
for each class $i$ to predict the probability that $y=i$.

On a new input $x$, to make a prediction, pick the class $i$ that
maximizes $\max_{i}h_{\theta}^{\left(i\right)}\left(x\right)$.


\section{Regularization}


\subsection{The problem of overfitting}

features 太少导致 underfitting(high bias)，而features太多就会导致overfitting(high
variants)，正如图\ref{fig:Underfitting-and-Overfitting-in-linear-regression}和图\ref{fig:Underfitting-and-Overfitting-in-logistic}所示。

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{7\lyxdot 1\lyxdot overfitting}
\par\end{centering}

\caption{\label{fig:Underfitting-and-Overfitting-in-linear-regression}Underfitting
and Overfitting in Linear Regression}
\end{figure}

\begin{description}
\item [{Overfitting}] If we have too many features, the learned hypothesis
may fit the training set very well($J\left(\theta\right)=\frac{1}{2m}\sum_{i=1}^{m}\left(h_{\theta}\left(x^{\left(i\right)}\right)-y^{\left(i\right)}\right)^{2}\approx0$),
but fail to generalize to new examples(predict prices on new examples).
\end{description}
\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{7\lyxdot 1\lyxdot overfitting2}
\par\end{centering}

\caption{\label{fig:Underfitting-and-Overfitting-in-logistic}Underfitting
and Overfitting in Logistic Regression}


\end{figure}



\subsubsection{Addressing overfitting}

Options:
\begin{enumerate}
\item Reduce number of features.

\begin{itemize}
\item Manually select which features to keep.
\item Model selection algorithm.
\end{itemize}
\item Regularization

\begin{itemize}
\item Keep all the features, but reduce magnitude/values of parameters $\theta_{j}$.（减小参数的权重）
\item Works well when we have a lot of features, each of which contributes
a bit to predicting $y$.
\end{itemize}
\end{enumerate}

\subsection{Cost function}


\subsubsection{Intuition}

如图\ref{fig:Penalize-parameters}所示，如果出现了过度拟合，我们可以使$\theta_{3}$和$\theta_{4}$变得非常小甚至接近于0，从而降低这两个参数对整个图形的贡献。如图\ref{fig:Penalize-parameters}所示，在原式后面加上$1000\theta_{3}^{2}+1000\theta_{4}^{2}$两个因子（其中1000是随便指定的比较大的值），这样，如果要使原式取最小值，那我们必须使$\theta_{3}$和$\theta_{4}$取值很小，从而达到我们的目的。

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{7\lyxdot 2\lyxdot Intuition}
\par\end{centering}

\caption{\label{fig:Penalize-parameters}Penalize parameters instead of removing
them}


\end{figure}



\subsubsection{Regularization}

Small values for parameters $\theta_{0},\theta_{1},\ldots,\theta_{n}$
\begin{itemize}
\item {}``Simpler'' hypothesis
\item Less prone(倾向) to overfitting.
\end{itemize}
\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{7\lyxdot 2\lyxdot Intuition2}
\par\end{centering}

\caption{\label{fig:Regularization}Regularization}


\end{figure}


如图\ref{fig:Regularization}所示%
\footnote{注意j是从1开始取值的。这是个习惯上的做法，实际上从0开始或从1开始对结果不会有太大影响(little difference)。%
}，Regularization对\textbf{每个}参数($\theta$)都乘以一个惩罚因子$\lambda$。What the
regularization parameter does is it controls the tradeoff between
the goal of fitting the data well and the goal of keeping the parameter
small, and therefore keeping the hypothesis simple.

但是如果$\lambda$取值太大，则会造成underfitting。道理很简单，right?


\subsection{Regularized linear regression}


\subsubsection{Gradient descent}

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"7.3.Regularized linear regression\string".png}
\par\end{centering}

\caption{\label{fig:Gradient-Descent-with-Regularization}Gradient Descent
with Regularization}


\end{figure}


注意 $1-\alpha\frac{\lambda}{m}$ 是小于1的，这就相当于把 $\theta_{j}$缩小了，而后面的部分和之前的公式是一样的。中间公式中括号内的部分正是对
$J\left(\theta\right)$ 求导的结果。 注意，这里有一处符号错误，$\frac{\lambda}{m}\theta_{j}$
前应该是+。


\subsubsection{Normal equation}

Gradient descent 只是两种线性回归拟合算法中的一个，另外一种是基于 normal equation 的，我们需要一个
design matrix $X_{m\times\left(n+1\right)}$和结果矢量y。X的每一行对应一个 training
example。y保存着每个training example的结果。关于算法的详细描述可参见\ref{sub:Normal-equation-=006B63=0089C4=0065B9=007A0B}

\begin{equation}
\theta=\left(X^{T}X+\lambda\begin{bmatrix}0\\
 & 1\\
 &  & \ddots\\
 &  &  & 1
\end{bmatrix}\right)^{-1}X^{T}y\label{eq:Normal-equation-with-regulariazion}
\end{equation}


上式中$\lambda$后面的矩阵是 $\left(n+1\right)\times\left(n+1\right)$的，如果去掉$\lambda$和其后的矩阵，那么就是之前学过的的Normal
Equation，这里是加上Regularization。其实等号后的部分正是令 cost function 求导为0的结果：$\frac{\delta}{\delta\theta_{j}}J\left(\theta\right)\overset{set}{=}0$。由于证明比较复杂，因此具体为什么是这个结果老师不作解释:D

我们知道，当 $m\leq n$ 时，公式\ref{eq:normal equation}中的$X^{T}X$ 是不可逆的，然而可以证明，当使用
Regularization后，加上Regularization因子后的矩阵一定是可逆的。


\subsection{Regularized logistic regression}


\subsubsection{Gradient Descent}

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"7.4.Regularized logistic regression\string".png}
\par\end{centering}

\caption{\label{fig:Cost-function-of-logistic-with-reg}Cost function of logistic
with reguarization}


\end{figure}


\begin{equation}
J\left(\theta\right)=-\left[\frac{1}{m}\sum_{i=1}^{m}\left(y^{\left(i\right)}\log h_{\theta}\left(x^{\left(i\right)}\right)+\left(1-y^{\left(i\right)}\right)\log\left(1-h_{\theta}\left(x^{\left(i\right)}\right)\right)\right)\right]+\frac{\lambda}{2m}\sum_{j=1}^{n}\theta_{j}^{2}\label{eq:cost func logistic regression with reg}
\end{equation}


在 logistic regression 中使用Regularization的cost function见图\ref{fig:Cost-function-of-logistic-with-reg}和公式\ref{eq:cost func logistic regression with reg}，需要注意j仍然是从1开始的。

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{7\lyxdot 4\lyxdot CostFuntion}
\par\end{centering}

\caption{\label{fig:Gradient-Descent-of-logistic-with-reg}Gradient Descent
of Logistic Regression with Regularization}
\end{figure}


经过Regularized的gradient descent如图\ref{fig:Gradient-Descent-of-logistic-with-reg}所示，该图中仍有一处符号错误：$\frac{\lambda}{m}\theta_{j}$
前应该是+。注意，虽然看起来图\ref{fig:Gradient-Descent-of-logistic-with-reg}中的公式和线性回归中的类似，但该图中的$h_{\theta}$和线性回归中的$h_{\theta}$是完全不同的函数。

同上一节一样，中括号中的部分是 $J\left(\theta\right)$ 的偏导。


\subsubsection{Advanced optimization}

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"7.4.Advanced optimization\string".png}
\par\end{centering}

\caption{\label{fig:Advanced-Optimization}Advanced Optimization}
\end{figure}


要想使用regularized的advanced optimization，只需要将 cost function 的定义进行如图\ref{fig:Advanced-Optimization}所示的修改即可，注意图中仍然存在符号错误。


\section{Neural Networks: Representation}


\subsection{Non-linear Hypotheses}

当输入的feature集巨大时，Logistic Regression将会力不从心。神经网络是用于计算复杂非线性回归问题(complex
non-linear hypotheses)的好方法。


\subsection{Neurons（神经元） and the Brain}
\begin{description}
\item [{Neuro-rewiring~experiments}] 比如把传入听觉中枢的神经re-wire到眼睛，那么听觉中枢会学习用眼睛看的功能。同一块大脑组织，其实可以处理听觉、视觉、触觉等等功能。看起来大脑有非常强大的学习算法:)
\end{description}
\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"8.2.Neurons and brain\string".png}
\par\end{centering}

\caption{大脑强大的学习能力}
\end{figure}



\subsection{Model representation I}


\subsubsection{Nuron in the brain}

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"8.3.1\string".nuron in the brain}
\par\end{centering}

\caption{\label{fig:=005927=008111=004E2D=007684=00795E=007ECF=005143=007ED3=006784}大脑中的神经元结构}
\end{figure}


大脑中的神经元结构如图\ref{fig:=005927=008111=004E2D=007684=00795E=007ECF=005143=007ED3=006784}所示，图中
Dendrite 是树突，也就是输入端，Axon是轴突，也就是输出端。


\subsubsection{Neuron model: losgistic unit}

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"8.3.1.neuron model:losistic unit\string".png}
\par\end{centering}

\caption{\label{fig:=004EBA=005DE5=00795E=007ECF=005143=006A21=00578B=00FF1A=00903B=008F91=005355=005143}人工神经元模型：逻辑单元}
\end{figure}


我们将大脑中的神经元类比到人工智能网络中，一个简单的神经网络可见图\ref{fig:=004EBA=005DE5=00795E=007ECF=005143=006A21=00578B=00FF1A=00903B=008F91=005355=005143}。

一般绘制神经网络图时会省略$x_{0}$，$x_{0}=1$ 称为bias unit或bias neuron。

When we talk about neural networks, sometimes we'll say that this
is a neural network with a sigmoid(logistic) \textbf{activation function}(激活函数).
This activation function in the neural network terminology is just
another term for that non-linear function $g\left(z\right)=\frac{1}{1+e^{-z}}$.

回归模型中的参数（$\theta$）在神经网络中有时被称为权重（weights）。


\subsubsection{Neural Network}

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"8.3.Neural Network\string".png}
\par\end{centering}

\caption{\label{fig:Neural-Network}Neural Network}
\end{figure}


图\ref{fig:Neural-Network}是一个三层的神经网络，其中$x_{1}$,$x_{2}$,$x_{3}$是输入层，The
third layer outputs the value that the hypothesis $h\left(x\right)$
computes.第一层经常称为输入层(input layer)，最后一层被称为输出层(output layer)，而位于中间的被称为隐藏层(hidden
layer)。关于这个神经网络是如何工作的，请参考图\ref{fig:Neural-Network(2)}。

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"8.3.Neural Network2\string".png}
\par\end{centering}

\caption{\label{fig:Neural-Network(2)}Neural Network(2)}
\end{figure}


需要注意图中的标号，正如图中所说，如果神经网络在第$j$层有$s_{j}$个单位，在$j+1$层有$s_{j+1}$个单位，那么$\Theta^{\left(j\right)}$将是一个$s_{j+1}\times\left(s_{j}+1\right)$的矩阵，如h图中$\Theta^{\left(1\right)}$就是$3\times4$的矩阵。


\subsection{Model representation II}


\subsubsection{Forward propagation: Vectorized implementation 前向传播：矢量化实现}

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"8.4.forward propagation\string".png}
\par\end{centering}

\caption{\label{fig:Forward-propagation:Vectorized-impl}Forward propagation:Vectorized
implementation}


\end{figure}


如图\ref{fig:Forward-propagation:Vectorized-impl}所示，将括号中的部分表示为$z_{i}^{\left(j\right)}$，那么计算过程可以使用图中右半部分的矩阵运算表示（输入层$x$使用$a^{\left(1\right)}$表示）。We
call this process of computing $h_{\theta}\left(x\right)$ \textbf{forward
propagation} because that we start of with the \textbf{activations}
of the input-units and then we \textbf{forward propagate} that to
the hidden layer and compute the activations of the hidden layer and
then we forward propagate that, and compute the activations of the
output layer, this process of computing the activations from the input
then the hidden then the output layer and that's also called forward
propagation.


\subsubsection{Neural Network learning its own features}

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"8.4.Neural network learning features\string".png}
\par\end{centering}

\caption{\label{fig:Neural-network-learning-its-own-features}Neural network
learning its own features}


\end{figure}


如图\ref{fig:Neural-network-learning-its-own-features}所示，如果将 input
layer 遮住，那么计算 $h_{\theta}\left(x\right)$ 的公式将如图中所示，可见与 Logistic Regression
的公式（公式\ref{eq:logistic regression hypothesis}）几乎相同（除了$\theta$变成了大写$\Theta$外\textasciitilde{}）。只不过在神经网络中，我们并不直接使用输入的
features -- $x_{1},x_{2},x_{3}$，而是使用 hidden layer 的 activations --
$a_{1}^{\left(2\right)},a_{2}^{\left(2\right)},a_{3}^{\left(2\right)}$。
It learned its own features to apply logistic regression. 这将比使用原始的输入
features （或他们的多项式形式 $x_{1}^{2},\, x_{1}x_{2},\, x_{2}^{2}\ldots$）来计算
logistic regression 产生更好的 hypotheses。


\subsection{Examples and intuitions I}


\subsubsection{Simple example: AND}

图\ref{fig:=00795E=007ECF=007F51=007EDC=004E2D=007684AND=00903B=008F91}为神经网络实现的AND逻辑。

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{8\lyxdot 5\lyxdot Example1}
\par\end{centering}

\caption{\label{fig:=00795E=007ECF=007F51=007EDC=004E2D=007684AND=00903B=008F91}神经网络中的AND逻辑}


\end{figure}



\subsection{Examples and intuitions II}

在本节将进行更为复杂的非线性问题的求解。

图\ref{fig:XNOR=00903B=008F91=007684=005B9E=0073B0=008FC7=007A0B}向我们展示了XNOR逻辑的具体实现过程。XNOR的真值表见图右下部分，即“相同为真，相异为假”，若以$x_{1}$和$x_{2}$为坐标轴，那么我们需要确定图\ref{fig:XNOR=00903B=008F91=007684=005B9E=0073B0=008FC7=007A0B}上部所示坐标系的
decision boundary。通过组合图中上部的三个简单神经网络，可以构造出XNOR的神经网络，即中间一层使用AND和 NOT
AND，输出层使用OR，得到的结果可以使用真值表检验。

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{8\lyxdot 6\lyxdot examples2}
\par\end{centering}

\caption{\label{fig:XNOR=00903B=008F91=007684=005B9E=0073B0=008FC7=007A0B}XNOR逻辑的实现过程}
\end{figure}


\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{8\lyxdot 6\lyxdot examples3}
\par\end{centering}

\caption{\label{fig:=00795E=007ECF=007F51=007EDC=007684=007ECF=005178=006848=004F8B=00FF1A=006570=005B57=008BC6=00522B}神经网络的经典案例：数字识别}
\end{figure}



\subsection{Multi-class classification}


\subsubsection{Multiple output units: One-vs-all}

如图\ref{fig:One-vs-All-in-neural-net}，四个输出项分别标识了是否是步行、是否是轿车、是否时摩托车和是否是卡车。可见类似于之前的One-vs-All方法，这里有四个逻辑标识符(logistic
classifier)。注意图中用的是约等号。

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"8.7.1.One vs All\string".png}
\par\end{centering}

\caption{\label{fig:One-vs-All-in-neural-net}One vs All in Neural Network}


\end{figure}


课后习题：Suppose you have a multi-class classification problem with three
classes, trained with a 3 layer network. Let $a_{2}^{(3)}=(h_{\Theta}(x))_{2}$
（注意$\Theta$要用大写）be the activation of the first output unit, and similarly
$a_{2}^{\left(3\right)}=(h_{\Theta}(x))2$ and $a_{3}^{(3)}=(h_{\Theta}(x))_{3}$.
Then for any input x, it must be the case that $a_{1}^{(3)}+a_{2}^{(3)}+a_{3}^{(3)}=1$。答案：错误，因为输出并非是概率，所以输出的总和并不一定是1。


\section{Neural Networks: Learning(the parameters)}


\subsection{Cost Function}


\subsubsection{Neural Network (Classification)}

\begin{figure}[!tbh]


\begin{centering}
\includegraphics[scale=0.75]{\string"9.1.Cost Function\string".png}\caption{\label{fig:Neural-Network-(Classification)}Neural Network (Classification)}

\par\end{centering}

\end{figure}


图\ref{fig:Neural-Network-(Classification)}解释：

L: 网络层数。

$s_{l}$: 第l层的节点个数（不包括bias节点）。

k: output layer 的节点个数。

我们将考虑binary classification 和 Muti-class classification($K\geqslant3$，$K=2$没意义)
两种情况。


\subsubsection{Cost function}


\paragraph{Logistic regression:}

\begin{equation}
J\left(\theta\right)=-\frac{1}{m}\left[\sum_{i=1}^{m}y^{\left(i\right)}\log h_{\theta}\left(x^{\left(i\right)}\right)+\left(1-y^{\left(i\right)}\right)\log\left(1-h_{\theta}\left(x^{\left(i\right)}\right)\right)\right]+\frac{\lambda}{2m}\sum_{j=1}^{n}\theta_{j}^{2}\label{eq:cost func logistic regression with reg2}
\end{equation}


The cost function we use for the neural network is going to be the
generalization of the one that we use for logistic regression(见公式\ref{eq:cost func logistic regression with reg}和\ref{eq:cost func logistic regression with reg2}). 


\paragraph{Neural network:(有K个输出)}

\[
h_{\Theta}\left(x\right)\in\mathbb{R}^{K}\qquad\left(h_{\Theta}\left(x\right)\right)_{i}=i^{th}\, output
\]


\begin{equation}
\begin{aligned}J\left(\Theta\right)=-\frac{1}{m}\left[\sum_{i=1}^{m}\sum_{k=1}^{K}y_{k}^{\left(i\right)}\log\left(h_{\Theta}\left(x^{\left(i\right)}\right)\right)_{k}+\left(1-y_{k}^{\left(i\right)}\right)\log\left(1-\left(h_{\Theta}\left(x^{\left(i\right)}\right)\right)_{k}\right)\right]\\
+\frac{\lambda}{2m}\sum_{l=1}^{L-1}\sum_{i=1}^{s_{l}}\sum_{j=1}^{s_{l+1}}\left(\Theta_{ji}^{\left(l\right)}\right)^{2}
\end{aligned}
\label{eq:cost function of neural network}
\end{equation}


For logistic regression, we used to minimize the cost function j of
theta that was shown above. For neural network, instead of having
basically just one logistic regression output unit, we have \textbf{K
of them}.

In the cost funtion, J of $\theta$, we have a sum from k = 1\textasciitilde{}K.
This is basically the sum over the K output unit. It's basically the
logistic regression algorithm's cost function but \textbf{summing}
that cost function over each of my output units in turn.

因此在公式\ref{eq:cost function of neural network}中，我们使用了$y_{k}$和$h_{\Theta}\left(\ldots\right)_{k}$来表示针对每一个输出项的y和hypothesis。虽然该公式的regularization项看起来非常复杂，但无非是在计算除了bias
unit（i=0）外所有的$\left(\Theta_{ji}^{\left(l\right)}\right)^{2}$的总和而已，和logistic
regression一样，从1开始（去除bisa unit）而不是从0开始仅仅是个惯例，即使从0开始也不会有太大的不同。


\subsection{Backpropagation Algorithm (to compute derivation of cost function)}


\subsubsection{Gradient Comutation}

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"9.2.backpropagation algorithm\string".png}
\par\end{centering}

\caption{\label{fig:Gradient-computation}Gradient computation}
\end{figure}


如图\ref{fig:Gradient-computation}，What we want to do is to focus on
how we can compute the \textbf{partial derivative }terms. 

让我们从只有一个training example $\left(x,y\right)$ 的情况开始，如图\ref{fig:Forward-propagation=008FC7=007A0B}所示，逐步计算cost
function的偏导。第一步为forward propagation，用来计算hypothesis输出。%
\footnote{在设计神经网络时，我们自然是没有现成的矩阵的（我们的任务也就是计算$\Theta$矩阵），然而却需要先用前向传播算法计算Hypothesis(这势必要用到$\Theta$)。虽然课程未做说明，但这里的$\Theta$往往是随机生成的值，具体可以参考第\ref{sub:Random-Initialization}节和\ref{sub:Putting-It-Together}节。这里只是提醒一下，以免看到相关内容时会困惑。%
}

貌似图中的 $a^{\left(1\right)}$应该加上bias unit（$a_{0}^{\left(1\right)}$）。

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"9.2.backpropagation algorithm2\string".png}
\par\end{centering}

\caption{\label{fig:Forward-propagation=008FC7=007A0B}Forward propagation过程}


\end{figure}


要计算偏导，下一步需要用到后向传播（backpropagation）算法。对该算法的直观理解就是对每个节点计算一个$\delta_{j}^{\left(l\right)}$，表示节点$j$在第$l$层的“误差”（error）。比如要计算输出层节点的“误差”，如图\ref{fig:back-propagation intuition}，那么只需计算每个节点$a_{j}^{\left(4\right)}$和结果$y_{i}$的差距即可。

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"9.2.backpropagation algorithm3\string".png}
\par\end{centering}

\caption{\label{fig:back-propagation intuition}backpropagation intuition}


\end{figure}


注意图\ref{fig:back-propagation intuition}中的算式可以矢量化为 $\delta^{\left(4\right)}=a^{\left(4\right)}-y=\left(h_{\Theta}\left(x\right)\right)-y$ 

下一步需要计算前面每一层的$\delta$，见式\ref{eq:compute delta for 3rd layer}、\ref{eq:compute delta for 2nd layer}。注意式\ref{eq:compute delta for 3rd layer}中$\left(\Theta^{\left(3\right)}\right)^{T}\delta^{\left(4\right)}$是一个矢量，$g^{\prime}\left(z^{\left(3\right)}\right)$也是一个矢量，他们之间使用的是点乘号（element
wise），表示按元素进行乘法运算（两矢量的对应元素分别相乘）。%
\footnote{$z^{\left(3\right)}$是5{*}1的矢量，然而如果按之前$\Theta$的定义，那么$\left(\Theta^{\left(3\right)}\right)^{T}\delta^{\left(4\right)}$的结果应该是6{*}1的。因此这里的$\Theta$应该不包括bias
unit，即$\Theta$是4{*}5的，这样结果就是5{*}1的了。编程训练中也是这样处理的。%
}

\begin{equation}
\delta^{\left(3\right)}=\left(\Theta^{\left(3\right)}\right)^{T}\delta^{\left(4\right)}\,.*g^{\prime}\left(z^{\left(3\right)}\right)\label{eq:compute delta for 3rd layer}
\end{equation}


\begin{equation}
\delta^{\left(2\right)}=\left(\Theta^{\left(2\right)}\right)^{T}\delta^{\left(3\right)}\,.*g^{\prime}\left(z^{\left(2\right)}\right)\label{eq:compute delta for 2nd layer}
\end{equation}


这里，$g^{\prime}\left(z^{\left(3\right)}\right)$ 是activation function
$g\left(z^{\left(3\right)}\right)$的导数:

\begin{equation}
g^{\prime}\left(z^{\left(3\right)}\right)=a^{\left(3\right)}\,.*\left(1-a^{\left(3\right)}\right)\label{eq:partial derivative of cost func in NN without reg}
\end{equation}


这里不对该式的得出进行推导（我没看懂是怎么得出来的）。\label{why:sigmoid=0051FD=006570=006C42=005BFC=007684=0063A8=005BFC}

注意没有 $\delta_{1}$这一说。

The name backpropagation comes from the fact that we start by computing
the delta term for the output layer and then we \textbf{go back} a
layer and compute the delta terms for that layer. So we are back propagating
the errors from the current layer to the earlier layer.

最后得到的求偏导的公式非常复杂，可以证明（过程比这个公式还要复杂，故略掉），如果忽略regularization($\lambda=0$),
那么我们需要的偏导数是：

\begin{equation}
\frac{\partial}{\partial\Theta_{ij}^{\left(l\right)}}J\left(\Theta\right)=\delta_{i}^{\left(l+1\right)}a_{j}^{\left(l\right)}\label{eq:partial derivative of cost func of logistic in NN without regularization}
\end{equation}



\subsubsection{Backpropagation algorithm}

如果training example不止一个，在这里设定有m个，如图\ref{fig:Backward-propagation-algorithm}所示，首先设置$\Delta_{ij}^{\left(l\right)}=0$(for
all l, i, j)，这里的$\Delta$是用来计算cost function的偏导的，而且正如即将看到的，$\Delta$其实是个累加数(Accumulator)。针对每个training
example执行图中所示循环，每次循环都更新一次$\Delta$。

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"9.2.backpropagation algorithm4\string".png}
\par\end{centering}

\caption{\label{fig:Backward-propagation-algorithm}Backpropagation algorithm}


\end{figure}


\footnote{图\ref{fig:Backward-propagation-algorithm}中计算$D_{ij}^{\left(l\right)}$的公式错误。应该为
$D_{ij}^{\left(l\right)}:=\frac{1}{m}\left(\Delta_{ij}^{\left(l\right)}+\lambda\Theta_{ij}^{\left(l\right)}\right)\qquad if\; j\neq0$%
}

也如图中所示，$\Delta$的计算可以矢量化为$\Delta^{\left(l\right)}:=\Delta^{\left(l\right)}+\delta^{\left(l+1\right)}\left(a^{\left(l\right)}\right)^{T}$的形式。

在循环外计算$D_{ij}^{\left(l\right)}$，分为$j=0$（bias unit）和$j\neq0$两种情况。

可以证明，最后求得的$D_{ij}^{\left(l\right)}$就是cost function的偏导：

\begin{equation}
\frac{\partial}{\partial\Theta_{ij}^{\left(l\right)}}J\left(\Theta\right)=D_{ij}^{\left(l\right)}\label{eq:partial derivative of cost func of logistic in NN with regularization}
\end{equation}


课堂习题（图\ref{fig:=008BFE=005802=007EC3=004E60=00FF1A=008BA1=007B97gradient=006B65=009AA4}）的答案就是求gradient过程的简单概括。

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"9.2.backpropagation algorithm5\string".png}
\par\end{centering}

\caption{\label{fig:=008BFE=005802=007EC3=004E60=00FF1A=008BA1=007B97gradient=006B65=009AA4}课堂练习：计算gradient步骤}
\end{figure}



\subsection{Implementation note: Unrolling parameters}

我们需要用到的函数一般都将$\theta$视为矢量，而神经网络中的$\Theta$是矩阵，因此需要将矩阵转化为矢量后才能使用之前介绍过的函数（如fminunc）进行计算（图\ref{fig:Need-to-unrol-params}）。

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"9.3.Unrolling parameters\string".png}
\par\end{centering}

\caption{\label{fig:Need-to-unrol-params}Need to unrol parameters}


\end{figure}


\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"9.3.Unrolling parameters2\string".png}
\par\end{centering}

\caption{\label{fig:=0077E9=009635=00548C=0077E2=0091CF=007684=004E92=008F6C}矩阵和矢量的互转}
\end{figure}


图\ref{fig:=0077E9=009635=00548C=0077E2=0091CF=007684=004E92=008F6C}所示便是矩阵到矢量和矢量到矩阵的转换方法。 


\subsection{Gradient Checking}

神经网络的后向算法可能会出现很多微妙的错误，因此最好在投入运作之前检查一下算法是否工作正常。

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"9.4.Gradient Checking\string".png}
\par\end{centering}

\caption{\label{fig:Gradient=009519=008BEF=0068C0=0067E5}Gradient错误检查}


\end{figure}


图\ref{fig:Gradient=009519=008BEF=0068C0=0067E5}是假设$\theta$是一个实数（$\theta\in\mathbb{R}$）的情况，我们通过检查斜率和我们估计的斜率值的误差是否在容许范围之内来判断算法是否工作正常。当$\theta$是矢量（$\theta\in\mathbb{R}$）时，我们计算的近似斜率如图\ref{fig:=008FD1=004F3C=00659C=007387=007684=008BA1=007B97}：

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"9.4.Gradient Checking2\string".png}
\par\end{centering}

\caption{\label{fig:=008FD1=004F3C=00659C=007387=007684=008BA1=007B97}近似斜率的计算}


\end{figure}


在Octave中实现如图\ref{fig:Octave=005B9E=0073B0=007684=008FD1=004F3C=00659C=007387}：

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"9.4.Gradient Checking3\string".png}
\par\end{centering}

\caption{\label{fig:Octave=005B9E=0073B0=007684=008FD1=004F3C=00659C=007387}Octave实现的近似斜率}
\end{figure}


实现提示：检查无误后，记得关掉Gradient checking(time costing)。相比后向传播，Gradient计算是非常耗时的（图\ref{fig:=004F7F=007528=00540E=005411=004F20=0064AD=00800C=004E0D=00662FGradient-descent=007684=00539F=0056E0}）。

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"9.4.Gradient Checking4\string".png}
\par\end{centering}

\caption{\label{fig:=004F7F=007528=00540E=005411=004F20=0064AD=00800C=004E0D=00662FGradient-descent=007684=00539F=0056E0}使用后向传播而不是Gradient
descent的原因}


\end{figure}



\subsection{Random Initialization\label{sub:Random-Initialization}}


\subsubsection{Initial value of $\Theta$}

For gradient descent and advanced optimization method, need initial
value for $\Theta$.

把$\Theta$初始化为零向量（在logistic regression中就是这么做的）在 神经网络中是行不通的，见图\ref{fig:=005C06=00521D=0059CB=005316=004E3A0=007684=0095EE=009898}，在每次更新（gradient
descent, etc）后，每个参数的权重永远是相同的。有时这被称作 The problem of symmetric weights.

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"9.5.Random Init\string".png}
\par\end{centering}

\caption{\label{fig:=005C06=00521D=0059CB=005316=004E3A0=007684=0095EE=009898}将$\Theta$初始化为0将导致每一层元素全部相同}
\end{figure}



\subsubsection{Random initialization: Symmetry(对称) breaking}

将每一个$\Theta_{ij}^{\left(l\right)}$初始化为$\left[-\epsilon,\epsilon\right]$之间的随机值：
\begin{lyxcode}
\begin{center}
Theta1~=~rand(10,11){*}(2{*}INIT\_EPSILON)~-~INIT\_EPSILON;
\par\end{center}
\end{lyxcode}

\subsection{Putting It Together\label{sub:Putting-It-Together}}


\subsubsection{Training a neural network}
\begin{enumerate}
\item The first thing you need to do is to pick some network architecture:

\begin{itemize}
\item Number of input units: Dimension of features $x^{\left(i\right)}$.
\item Number of output units: Number of classes.
\item Reasonable default: 1 hidden layer, or if >1 hidden layer, have same
number of hidden units in every layer.
\item Usually the number of hidden units in each layer will be comparable
to the dimension of $x$. Same number or 3 or 4 times of that(usually
the more the better).
\end{itemize}
\item Randomly initialize weights.
\item Implement forward propagation to get $h_{\Theta}\left(x^{\left(i\right)}\right)$
for any $x^{\left(i\right)}$.
\item Implement code to compute cost function $J\left(\Theta\right)$.
\item Implement backprop to compute partial derivatives $\frac{\partial}{\partial\Theta_{jk}^{\left(l\right)}}J\left(\Theta\right)$.


\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"9.6.put together\string".png}
\par\end{centering}

\caption{\label{fig:backpropagation-contour}backpropagation contour}


\end{figure}



图\ref{fig:backpropagation-contour}为后向传播算法概述，完整算法见 \ref{fig:Backward-propagation-algorithm}。

\item Use gradient checking to compare $\frac{\partial}{\partial\Theta_{jk}^{\left(l\right)}}J\left(\Theta\right)$
computed using backpropagation vs. using numerical estimate of gradient
of $J\left(\Theta\right)$.\\
Then disable gradient checking code.
\item Use gradient descent or advanced optimization method with backpropatation(
to compute $\frac{\partial}{\partial\Theta_{jk}^{\left(l\right)}}J\left(\Theta\right)$
) to try to minimize $J\left(\Theta\right)$ as a function of parameters
$\Theta$.
\end{enumerate}
\textbf{注意}：在神经网络中，$J\left(\Theta\right)$ 是 non-convex 的。所以s理论上可能会得到局部最优解。不过在实践中这并不是一个大问题，通常得到的解已足够令人满意。

Gradient descent 的直观描述见图\ref{fig:=0056DE=00987EGradient-descent}。

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"9.6.put together2\string".png}
\par\end{centering}

\caption{\label{fig:=0056DE=00987EGradient-descent}回顾Gradient descent}


\end{figure}


What gradient descent does is starting from some random initial point,
and it will repeatedly go downhill. And so what backpropagation is
doing is computing the direction of the gradient, and what gradient
descent is doing is taking little steps downhill untill hopefully
it gets to a pretty good local optimum.

When you implement backpropagation and use gradient descent or one
of the advanced optimization methods, this picture sort of explaining
what the algorithm is doing.


\section{Advice for applying machine learning}


\subsection{Deciding what to try next}

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"10.1.Deciding what to do next\string".png}
\par\end{centering}

\caption{\label{fig:What-to-try-next}What to try next}


\end{figure}


如图\ref{fig:What-to-try-next}，在之后的课程里，将会介绍Machine learning diagnostic.

It's a test that you can run to gain insight what is/isn't working
with a learning algorithm, and gain guidance as to how best to improve
its performance.


\subsection{Evaluating a hypothesis}

我们可以把hypothesis画出来，判断是否出现overfitting 或 underfitting. 可如果features 数量很多的话，画图就不是什么好主意了。

一般化的方法是将dataset 分割为两部分：第一部分用作training set, 而第二部分用来做test set。分割的比例大概是7:3。在分割前先对dataset随机排序一下（如果其排列不是随机的话）。


\subsubsection{Training/testing procedure for linear regression}

见图\ref{fig:Training/testing-for-linear-gregression}。

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"10.2.procedure for linear regression\string".png}
\par\end{centering}

\caption{\label{fig:Training/testing-for-linear-gregression}Training/testing
procedure for linear regression}


\end{figure}



\subsubsection{Training/testing procedure for logistic regression(classification)}

图\ref{fig:Training/testing-procedure-for-classification}给出了两种检验学习质量的方法，一种是使用cost
function，另一种称为misclassification error。不论使用哪种方法，如果算出的误差偏大，那么说明机器学习的质量偏低。

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"10.2.procedure for logistic regression\string".png}
\par\end{centering}

\caption{\label{fig:Training/testing-procedure-for-classification}Training/testing
procedure for classification}


\end{figure}



\subsection{Model selection and training/validation/test sets}

Suppose you'd like to decide what the degree of polynomial to fit
to a data set, sort of what features to include to give you a learning
algorithm. Or suppose you'd like to choose the regularization parameter
$\lambda$ for the learning algorithm. These are called \textbf{model
selection problems}.

在model selection 问题中，我们将把data set分成trainig、validation 和 test 三部分，而不只是
training 和 test 两部分。

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"10.3.model selection\string".png}
\par\end{centering}

\caption{\label{fig:Overfitting-example}Overfitting example}


\end{figure}


\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"10.3.model selection2\string".png}
\par\end{centering}

\caption{\label{fig:Model-slection}Model slection}
\end{figure}


如图\ref{fig:Model-slection}所示，假定我们列出d=1到d=10（d 表示多项式的维度）10个模型，然后计算每个模型的测试误差(test
error)$J_{test}\left(\theta\right)$，最后选择测试误差最小的模型。假设我们最终选择的模型是d=5的多项式，可以看到，使用
$J_{test}\left(\theta^{\left(5\right)}\right)$来估计模型的归纳质量是不公平的。因为What
we done is we fit the extra parameter $d$ to the test set（即找出d的最小值），那么我们据此选择的模型得到的
$\Theta$ 可能过于乐观的估计了它的归纳效果。 也就是说，建立在 test set 上的估计是不全面的。

现在我们将数据分成三部分： Training set, Cross validation set 和 Test set，大概是6:2:2的比例，见图\ref{fig:Evaluating-hypothesis}。


\subsubsection{Evaluating your hypothesis}

\begin{figure}[!tbh]
\begin{centering}
\includegraphics[scale=0.75]{\string"10.3.model selection3\string".png}
\par\end{centering}

\caption{\label{fig:Evaluating-hypothesis}Evaluating hypothesis}


\end{figure}



\subsubsection{Train/validation/test error}

Training error:

\[
J_{train}\left(\theta\right)=\frac{1}{2m}\sum_{i=1}^{m}\left(h_{\theta}\left(x^{\left(i\right)}\right)-y^{\left(i\right)}\right)^{2}
\]


Cross Validation error:

\[
J_{cv}\left(\theta\right)=\frac{1}{2m_{cv}}\sum_{i=1}^{m_{cv}}\left(h_{\theta}\left(x_{cv}^{\left(i\right)}\right)-y_{cv}^{\left(i\right)}\right)^{2}
\]


Test error:

\[
J_{test}\left(\theta\right)=\frac{1}{2m_{test}}\sum_{i=1}^{m_{test}}\left(h_{\theta}\left(x_{test}^{\left(i\right)}\right)-y_{test}^{\left(i\right)}\right)^{2}
\]


So when we fits the model selection problem by this, instead of using
the test set to select the model, we're instead going to use validation
set or the cross-validation set to select the model.

\includegraphics{\string"10.3.model selection4\string".png}

\includegraphics{\string"10.3.model selection5\string".png}我承认我没看懂……\label{why:validation vs. test set}

\includegraphics{10\lyxdot 3\lyxdot excercise}


\subsection{Diagnosing bias vs. variance}

If you run the learning algorithm and it doesn't do as well as you're
hoping, almost all the time it will be because you have either a high
bias problem or a high variance problem. In other words they're either
an underfitting problem or an overfitting problem.

\includegraphics{\string"10.4.bias vs variance\string".png}


\subsection{Regularization and bias/variance}

\includegraphics{10\lyxdot 5\lyxdot regularization}

How can we automatically choose a good value for the regularization
parameter $\lambda$ ?


\subsubsection{Choosing the regularization parameter $\lambda$}

\includegraphics{10\lyxdot 5\lyxdot regularization2}

$J_{train}\left(\theta\right)$、$J_{cv}\left(\theta\right)$和$J_{test}\left(\theta\right)$
都没有regularization。

\includegraphics{10\lyxdot 5\lyxdot regularization3}

选择一个使Cross validation error最小的 $\lambda$ 即可。选定之后，计算该 $\theta$ 的test
error: $J_{test}\left(\Theta^{\left(?\right)}\right)$ 来检查其在test set
上的表现如何。


\subsubsection{Bias/variance as a function of the regularization parameter $\lambda$}

\includegraphics{10\lyxdot 5\lyxdot regularization4}

\includegraphics{10\lyxdot 5\lyxdot regularization5}


\subsection{Learning curves}

\includegraphics{\string"10.6.Learning curves\string".png}


\subsubsection{High bias}

\includegraphics{\string"10.6.Learning curves high bias\string".png}

Both $J_{cv}\left(\Theta\right)$ and $J_{train}\left(\Theta\right)$
are high.


\subsubsection{High variance}

\includegraphics{\string"10.6.Learning curves high variance\string".png}


\subsection{Deciding what to try next (revisited)}

\includegraphics{10\lyxdot 7\lyxdot revisited}


\subsubsection{Neural networks and overfitting}

如果要增加神经网络的层数，可以测试一下不同层数的$J_{cv}\left(\Theta\right)$ 以找到最佳结果。

\includegraphics{\string"10.7.neural network\string".png}

\includegraphics{\string"10.7.neural network2\string".png}


\section{Machine Learning System Design}


\subsection{Prioritizing what to work on: Spam classification example}

采用 Supervised leaning 来构建一个垃圾邮件分类器，问题就在于如何选择 email 的features。 而输出y则是
spam(1) 或 not spam(0)两个值。

\includegraphics{\string"11.1 Spam classifier\string".png}

Note: In practice, take most frequently occurring $n$ words (10,000
to 50,000) in training set, rather than manually pick 100 words.

\textbf{How to spend your time to make it have low error?}

\includegraphics{\string"11.1 Spam classifier2\string".png}

\includegraphics{\string"11.1 Spam classifier3\string".png}


\subsection{Error analysis}


\subsubsection{Recommended approach}

\includegraphics{\string"11.2.error analysing\string".png}

先用24小时的时间构建一个相当简单而且脏乱的系统。然后使用cross-validation data来测试。之后通过画学习曲线和误差分析来优化系统。


\subsubsection{Error Analysis}

\includegraphics{\string"11.2.error analysing2\string".png}


\subsubsection{The importance of numerical evaluation}

\includegraphics{\string"11.2.error analysing3\string".png}

\includegraphics{\string"11.2.error analysing4\string".png}

\textbf{强烈建议}使用 cross validation error 而不是 test error 来进行误差分析。


\subsection{Error metrics for skewed classes}


\subsubsection{Cancer classification example}

\includegraphics{\string"11.3.Skewed class\string".png}

在skewed class（样本中某一类别出现的频率非常之小）的情况下，使用分类准确率将变得非常困难（比如上例，将诊断正确率从99.2\%提升到99.5\%，谁知道是不是算法更先进了还是单纯的预测出更多的y=0？）

对于skewed class问题，我们可能需要别的 error metric / evaluation metric。


\subsubsection{Pricision/Recall}

\includegraphics{\string"11.3.Precision Recall\string".png}

\includegraphics{\string"11.3.Precision Recall2\string".png}

Precision 和 recall 的取值越高越有利。特别地，如果像上一张幻灯片那样所有诊断结果都为0（良性），那么将得到为0的precision和recall值。

所以，如果我们得到了很高的 precision 和 recall ，那么我们可以相信我们的学习算法，即使样本是非常skewed的情况。


\subsection{Trading off precision and recall}

\includegraphics{\string"11.4.Trading off precision and recall\string".png}

当我们将阈值从0.5改成更高的值，以达到只有当我们非常自信时才预测为癌症，那么这会带来更高的precision，和更低的recall。

\includegraphics{\string"11.4.Trading off precision and recall2\string".png}

如果我们宁愿错诊也不想让病人错过治疗，那么 就需要调低阈值，这样就会带来更高的recall和更低的precision。


\subsubsection{$F_{1}$ Score (F score)}

\includegraphics{\string"11.4.Trading off precision and recall3\string".png}

现在一个学习算法有两个变量来描述，我们希望使用一个单值来衡量一个学习算法。使用平均值是相当没用的方式。这里我们使用 $F_{1}$
Score 来描述算法的质量。

\includegraphics{\string"11.4.Trading off precision and recall4\string".png}

那么，很明显：

\includegraphics{\string"11.4.Trading off precision and recall5\string".png}


\subsection{Data for Machine Learning}

\includegraphics{11\lyxdot 5}

\includegraphics{11\lyxdot 5\lyxdot 2}
\end{document}
